# -*- coding: utf-8 -*-
"""Untitled34.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B8L9czl6EsM1PkXYVYqkS34iSD4Kh_M7
"""

!pip install pandas 
!pip install numpy
!pip install scikit-learn==0.24.1
!pip install seaborn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.ticker import PercentFormatter
import seaborn as sb
import joblib

data = pd.read_csv('sample_data/Q1.csv')
data.head()

data.info()

"""Melihat informasi awal data dan mengecek apakah ada ketimpangan jumlah data non-null (indikasi ada data null). Terlihat bahwa semuanya memiliki nilai non-null yang sama berarti tidak ada missing data """

data.describe().T

"""Meninjau statistik dari data. Dilihat dari standard deviasi, data yang paling seragam adalah CHP1Vib1 sedangkan paling terdispersi adalah CHP2Temp2.   """

fig,ax = plt.subplots(figsize=(20,10))
sb.heatmap(data.loc[:,data.columns != "Fault" ].corr(),ax=ax,annot=True)
ax.set_title("Correlation Plot Training Data")

"""Terlihat dari plot, semua atribut menunjukkan korelasi positif dengan nilai yang berbeda-beda. Yang tertinggi antara CHP1Vib1 dengan CHP1Vib2 sedangkan yang terkecil antara CHP2Temp1 dengan CHP1Vib1.   """

data.columns.values

data_numeric = data.copy().drop(['Timestamp','Fault'],1)

fig1,ax1 = plt.subplots(figsize=(20,10))
ax1 = sb.boxplot(data=data_numeric, orient="h", palette="Set2")
ax1.set_title("Box-Plot Training Data")

"""Pada boxplot, terlihat banyak outliers (extreme-low) pada CHP1Temp1(Deg C). Hal ini bisa berpengaruh pada proses learning model. Hal ini mungkin perlu investigasi lebih lanjut untuk penanganan kedepannya. Sedangkan atribut lain, ada yang berupa normal distribution dan skewed. Untuk skewed, bisa diterapkan transformation untuk membuat distribusinya mendekati normal/bell-shaped."""

plt.figure(figsize=(12,8))
plt.title("Distribusi Faulty")
plt.ylabel('Jumlah')
sb.distplot(data['Fault'],kde=False);

"""Terdapat perbedaan kelas antara Fault (1) dengan Normal (0). Hal ini akan berpengaruh terhadap learning dari model yang digunakan. Hal ini bisa diatasi dengan pembagian stratifikasi saat train/train split atau parameter class_weight pada algoritma ML seperti Random Forest """

from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV,RandomizedSearchCV,cross_val_score,cross_validate
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import mean_squared_error,make_scorer, mean_absolute_error
from sklearn.metrics import classification_report,confusion_matrix,f1_score,precision_score,recall_score,roc_auc_score,roc_curve, plot_confusion_matrix
from math import sqrt
from sklearn.linear_model import SGDClassifier, LogisticRegression
from sklearn.svm import SVC
from typing import List

def split_training_stratified(data_train:object,target_column:str,
                              test_size:float=0.2,splits:int=1)->List[object]:
    """
    Menyamaratakan distribusi data pada subset terkait dan dipisah sesuai dengan porsi yang telah ditentukan
    
    Parameters:
        data_train      : Data (atribut) untuk training
        target_column   : Atribut yang diprediksi pada data_train
        test_size       : Porsi subset data untuk test hasil training
        splits          : Pembagian subset/batch data training oleh algoritma stratified-split scikit-learn
    Output:
        X_train [List]  : Subset data training
        y_train [List]  : Target value untuk data training
        X_test  [List]  : Subset data testing
        y_test  [List]  : Target value untuk data testing
    """
    df_train = data_train.copy()
    X = df_train.drop(target_column,axis=1)
    y = df_train[target_column]
    Split = StratifiedShuffleSplit(n_splits=splits, test_size=test_size)
    for train_index, test_index in Split.split(X, y):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y[train_index], y[test_index]
    return X_train,X_test,y_train,y_test

def split_training(data_train:object,target_column:str,test_size:float=0.2,shuffle:bool=True)->List[object]:
    """
    Memisahkan data training (tanpa proses stratifikasi) sesuai dengan porsi yang ditentukan.
    
    Parameters:
        data_train      : Data (atribut) untuk training
        target_column   : Atribut yang diprediksi pada data_train
        test_size       : Porsi subset data untuk test hasil training
        shuffle         : Pengacakan data training untuk meminimalkan bias
    Output:
        X_train [List]  : Subset data training
        y_train [List]  : Target value untuk data training
        X_test  [List]  : Subset data testing
        y_test  [List]  : Target value untuk data testing
    """
    df_train2 = data_train.copy().sample(frac=1)
    X = df_train2.drop(target_column,axis=1)
    y = df_train2[target_column]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=101, shuffle=shuffle)
    return X_train, X_test, y_train, y_test

def normalize(data_train:object,data_test:object,
              types:str="MinMax")->object:
    """
    Penyamarataan nilai atribute dalam rentang/skala yang sama. 
    
    Parameters:
        data_train      : Data (atribut) untuk training
        data_test       : Data (atribut) untuk testing
        types           : Tipe normalisasi (Minmax, Standard, Robust)
    Output:
        scaled_train [object]  : Data train yang telah dinormalisasi
        scaled_test  [object]  : Data test yang telah dinormalisasi
        scaler       [object]  : Scaling variable dengan catatan skala data terkait
    """
    scaler = None
    if types == "Standard":
        scaler = StandardScaler()
    elif types == "Robust":
        scaler = RobustScaler()
    else:
        scaler = MinMaxScaler()
    scaler.fit(data_train)
    scaled_train = scaler.transform(data_train)
    scaled_test = scaler.transform(data_test)
    return scaled_train,scaled_test,scaler

def scale_transform(data:object,scaler:object) -> List:
    """
    Mengubah nilai data dengan skala tertentu.

    Parameters:
        data     : Objek data (dataframe)
        scaler   : Pengubah (objek dari sklearn)
    Output:
        scaled_data [List] : Data yang sesuai dengan skala 
    """
    data_copy = data.copy()
    return scaler.transform(data_copy)

def RMSE(y_pred:List,y_true:List)->float:
    """
    Metrik penilaian model berdasarkan root-mean-squared-error. 
    
    Parameters:
        y_pred      : Target value hasil prediksi model
        y_true      : Target value sebenarnya
    Output:
        error (float) : Nilai RMSE
    """
    return mean_squared_error(y_pred,y_true)**0.5

def model_fitting(X:List,y:List,model_dict:dict={})->dict:
    """
    Training atau fitting model dengan data training 
    
    Parameters:
        X           : Subset data training
        y           : Subset target training
        model_dict  : Kumpulan model training
    Output:
        metrik [dict]  : Kumpulan metrik model terkait
    """
    result = {}
    for name,estimator in model_dict.items():
        estimator.fit(X,y)
        result_est = estimator.score(X,y)*100
        result[name] = float("{:.2f}".format(result_est))
    return result

def cross_validate_model(X:List,y:List,folds:int=3,model_dict:dict={})->dict:
    """
    Training atau fitting model dengan metode cross-validation 
    
    Parameters:
        X           : Subset data training
        y           : Subset target training
        model_dict  : Kumpulan model training
        folds       : Jumlah partisi subset data untuk cross-validation
    Output:
        metrik [dict]  : Kumpulan metrik model terkait
    """
    result = {}
    for name,estimator in model_dict.items():
        cv_results = cross_validate(estimator, X, y, cv=folds)
        result_est = np.mean(cv_results['test_score'])*100
        result[name] = float("{:.2f}".format(result_est))
    return result

def model_testing(X:List,y:List,model_dict:dict={})->dict:
    """
    Testing model terkait dengan true target 
    
    Parameters:
        X           : Subset data training
        y           : Subset target training (true)
        model_dict  : Kumpulan model training
    Output:
        metrik [dict]  : Kumpulan metrik model terkait
    """
    result = {}
    for name,estimator in model_dict.items():
        result_est = estimator.score(X,y) * 100
        result[name] = float("{:.2f}".format(result_est))
    return result

def model_predict(X:List,y_true:List,model_dict:dict={})->dict:
    """
    Prediksi target data blank dengan model 
    
    Parameters:
        X           : Subset data testing
        y           : Subset target training (true)
        model_dict  : Kumpulan model training
    Output:
        metrik [dict]  : Kumpulan metrik model terkait
    """
    result = {}
    result['True'] = y_true
    for name,estimator in model_dict.items():
        result_est = estimator.predict(X)
        result[name] = result_est
    data = pd.DataFrame(result)
    data.reset_index(inplace=True)
    data.drop('index',axis=1,inplace=True)
    return data

def model_metric(y_true:List,model_dict:dict={})->dict:
    """
    Metrik prediksi target oleh model training 
    
    Parameters:
        y_true      : Subset target (true)
        model_dict  : Kumpulan model training
    Output:
        metrik [dict]  : Kumpulan metrik model terkait
    """
    result = {}
    report = {}
    for name,arrays in model_dict.items():
        result_est = confusion_matrix(arrays,y_true)
        report_est = classification_report(arrays,y_true)
        result[name] = result_est
        report[name] = report_est
    return result,report

def model_metric_ROC(y_true:List,X_test:List,model_dict:dict={})->dict:
    """
    Metrik MAE prediksi target oleh model training
    
    Parameters:
        y_true      : Subset target (true)
        model_dict  : Kumpulan model training
    Output:
        metrik [dict]  : Kumpulan metrik model terkait
    """
    result = {}
    for name,arrays in model_dict.items():
        result_est = roc_auc_score(y_true,arrays.predict_proba(X)[:,1])
        result[name] = result_est
    return result

def save_model(model_dict:dict={},prefix:str='') -> object:
    """
    Save ML model into joblib object
    
    Parameters:
        model_dict  : Kumpulan model training
    Output:
        ML_model [object]  : Model ML dengan format joblib
    """
    for name,model in model_dict.items():
        joblib.dump(model,prefix+name+'.joblib')

def save_scaler(scaler:object,name:str) -> object:
    """
    Save scaler model into joblib object
    
    Parameters:
        scaler  : Model scaler
    Output:
        Scaler_model [object]  : Model scaler dengan format joblib
    """
    joblib.dump(scaler,name+'.joblib')
    

rmse = make_scorer(RMSE,greater_is_better=False)

# DROP Timestamp
data.drop(['Timestamp'],axis=1,inplace=True)

"""Men-drop atribute timestamp karena berupa data non-numerik dan tidak digunakan lebih jauh dalam algoritma supervised classification."""

X_train, X_predict, y_train, y_predict = split_training(data,target_column='Fault',test_size=0.2,shuffle=False)

"""Pembagian ini dilakukan untuk memisahkan data training dan prediction. Data training akan dipisah lagi menjadi data training dan data test/validation sedangkan data prediction akan digunakan untuk menguji akurasi model pada data yang belum pernah dilihat. Untuk porsinya, mengikuti pattern umum yaitu 80:20."""

data_train = pd.concat([X_train,y_train],axis=1).reset_index().drop('index',1)
data_train.head()

X_Train, X_Test, y_Train, y_Test = split_training(data_train,target_column='Fault',test_size=0.2,shuffle=True)

print(y_Train.value_counts(),'Random-Shuffle Subset Training\n')
print(y_Test.value_counts(),'Random-Shuffle Subset Testing\n')
print(y_train.value_counts(),'Data Training\n')

"""Hasil dari random-shuffle train_test_split menggambarkan distribusi class yang berbeda dimana pada subset training, class Fault (1) sekitar 64,85 persen sedangkan pada subset testing sekitar 61,63 persen. Pada data training, class Fault (1) sekitar 64,2 persen. Hal ini akan berpengaruh pada hasil training dan testing saat model-fitting yang secara tidak langsung memengaruhi hasil prediksi pada subset prediction. Parameter 'shuffle' berguna untuk mengurangi pengaruh bias yang diakibatkan pola data mentah. """

scaled_train,scaled_test,scaler = normalize(X_Train,X_Test)

"""Normalisasi data dilakukan untuk peningkatan learning dan konsistensi model. Dengan skala yang sama, model dapat lebih cepat mencapat titik konvergensi dan akurasi yang didapatkan lebih tinggi. Skala yang digunakan berasal dari subset training yang kemudian diaplikasikan pada subset training dan testing. Hal ini dilakukan untuk mencegah data-leak pada subset testing."""

model_learning = {
    'RandomForest':RandomForestClassifier(),
    'DecisionTree':DecisionTreeClassifier(),
    'GradientBoosting':GradientBoostingClassifier(),
    'LogisticRegression':LogisticRegression(),
    'AdaBoost':AdaBoostClassifier(),
    'SGD':SGDClassifier(),
    'Bagging':BaggingClassifier()
}
early_cross = cross_validate_model(scaled_train,y_Train,folds=5,model_dict=model_learning)
early_result = model_fitting(scaled_train,y_Train,model_learning)
early_test = model_testing(scaled_test,y_Test,model_learning)
early_dev = {name: float("{:.2f}".format(early_result[name]-early_test[name])) for name in early_result}
print(f'Learning Result :  \n', early_result)
print('\n')
print(f'Cross_VAL Result :  \n',early_cross)
print('\n')
print(f'Testing Result :  \n',early_test)
print('\n')
print(f'Deviation of Training and Testing : \n',early_dev)

"""Hasil dari learning berupa model-fitting dan cross-validation menunjukkan nilai score (akurasi) yang tinggi serta deviasi antara keduanya tidak terlalu besar. Hal ini berarti model telah mempelajari pola subset training dan memprediksi subset testing dengan baik.  """

print('RANDOMIZED MODEL SCORES ON PREDICTION SET (UNSEEN DATA)')
scaled_predict = scale_transform(X_predict,scaler)
tunning_score = model_testing(scaled_predict,y_predict,model_learning)
tunning_score

"""Hasil prediksi dari learning model menunjukkan nilai score (akurasi) yang tinggi juga. Hal ini berarti model tidak mengalami overfitting (nilai akurasi prediksi lebih kecil dibanding training) ataupun underfitting (nilai akurasi training lebih kecil sehingga berdampak sebanding pada akurasi prediksi).  """

X_Train_S, X_Test_S, y_Train_S, y_Test_S = split_training_stratified(data_train,target_column='Fault',test_size=0.2,splits=10)

"""Untuk perbandingan lebih lanjut, digunakan data dengan distribusi sebanding dengan data awal (stratifikasi). Selanjutnya akan dilakukan model fitting untuk melihat perbedaan nilai akurasi yang didapatkan. """

print(y_Train_S.value_counts(),'Stratified Subset Training\n')
print(y_Test_S.value_counts(),'Stratified Subset Testing\n')
print(y_train.value_counts(),'Data Training\n')

"""Hasil dari stratified train_test_split menggambarkan distribusi class yang hampir sama dimana pada subset training, class Fault (1) sekitar 64,21 persen sedangkan pada subset testing sekitar 63,7 persen. Pada data training, class Fault (1) sekitar 64,2 persen. Hal ini tentunya akan berpengaruh pada hasil training dan testing. Distribusi subset yang bermiripan dengan data mentah akan membantu model mempelajari pola seakan-akan dari data mentah sehingga tingkat akurasi prediksi bisa jadi lebih tinggi. """

scaled_train_S,scaled_test_S,scaler_S = normalize(X_Train_S,X_Test_S)

model_learning_S = {
    'RandomForest':RandomForestClassifier(),
    'DecisionTree':DecisionTreeClassifier(),
    'GradientBoosting':GradientBoostingClassifier(),
    'LogisticRegression':LogisticRegression(),
    'AdaBoost':AdaBoostClassifier(),
    'SGD':SGDClassifier(),
    'Bagging':BaggingClassifier()
}
early_cross_S = cross_validate_model(scaled_train_S,y_Train_S,folds=5,model_dict=model_learning_S)
early_result_S = model_fitting(scaled_train_S,y_Train_S,model_learning_S)
early_test_S = model_testing(scaled_test_S,y_Test_S,model_learning_S)
early_dev_S = {name: float("{:.2f}".format(early_result_S[name]-early_test_S[name])) for name in early_result_S}
print(f'Learning Result :  \n', early_result_S)
print('\n')
print(f'Cross_VAL Result :  \n',early_cross_S)
print('\n')
print(f'Testing Result :  \n',early_test_S)
print('\n')
print(f'Deviation of Training and Testing : \n',early_dev_S)

print('RANDOMIZED MODEL SCORES ON PREDICTION SET (UNSEEN DATA)')
scaled_predict_S = scale_transform(X_predict,scaler_S)
prediction_score = model_testing(scaled_predict_S,y_predict,model_learning_S)
prediction_score

"""Jika dibandingkan dengan random-shuffle split, hasil training stratified split cenderung lebih tinggi. Hal ini secara tidak langsung membuktikan bahwa distribusi subset data berpengaruh terhadap hasil training, testing, dan prediksi."""

save_model(model_learning,'NS_')
save_model(model_learning_S)
save_scaler(scaler,'RS')
save_scaler(scaler_S,'NS')